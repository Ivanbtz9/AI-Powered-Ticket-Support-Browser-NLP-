@misc{etude2015,
	title        = {Research-paper recommender systems: a literature survey},
	howpublished = {\url{https://kops.uni-konstanz.de/entities/publication/861ddd16-fbc6-4ee4-a77f-6bba081041f3}},
	note         = {Accédé le [08-02-2024]},
}

@misc{TFIDFsumup,
	title        = {Intelligence artificielle: Résumer un texte grâce au TF IDF},
	howpublished = {\url{https://datascientest.com/tf-idf-intelligence-artificielle}},
	note         = {Accédé le [08-02-2024]},
}

@misc{Wordpiece,
	title        = {Japanese and Korean voice search},
	howpublished = {\url{https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37842.pdf}},
	note         = {Accédé le [14-03-2024]},
}

@misc{BPE,
	title        = {Neural Machine Translation of Rare Words with Subword Units},
	howpublished = {\url{https://aclanthology.org/P16-1162.pdf}},
	note         = {Accédé le [14-03-2024]},
}

@misc{video_embedding,
	title        = {Video (min 18) : What are Transformer Models and how do they work?},
	howpublished = {\url{https://www.youtube.com/watch?v=qaWMOYf4ri8}},
	note         = {Accédé le [14-03-2024]},
}

@misc{wordpiecehuggingface,
	title        = {WordPiece tokenization : \\
	\url{https://huggingface.co/learn/nlp-course/en/chapter6/6} },
	note         = {Accédé le [15-03-2024]},
}

@misc{word2vec,
	title        = {Word2vec},
	howpublished = {\url{https://en.wikipedia.org/wiki/Word2vec}},
	note         = {Accédé le [15-03-2024]},
}

@misc{openai_tokenizer,
	title        = {Openai tokenizer},
	howpublished = {\url{https://platform.openai.com/tokenizer}},
	note         = {Accédé le [7-05-2024]},
}

@misc{Distributed_Representations_of_Words,
	title        = {Distributed Representations of Words and Phrases
	and their Compositionality},
	howpublished = {\url{https://arxiv.org/pdf/1310.4546}},
	note         = {Accédé le [7-05-2024]},
}

@misc{TF_IDF_measures,
	title        = {An information-theoretic perspective of tf–idf measures},
	howpublished = {\url{https://ccc.inaoep.mx/~villasen/index_archivos/cursoTL/articulos/Aizawa-tf-idfMeasures.pdf}},
	note         = {Accédé le [08-05-2024]},
}

@misc{CosineSimilarity,
	title        = {Cosine Similarity},
	howpublished = {\url{https://www.learndatasci.com/glossary/cosine-similarity/}},
	note         = {Accédé le [08-05-2024]},
}

@misc{a_i_a_y_n,
	title        = {Attention Is All You Need},
	howpublished = {\url{https://arxiv.org/abs/1706.03762}},
	note         = {Accédé le [10-05-2024]},
}

@misc{bert_paper,
	title        = {BERT: Pre-training of Deep Bidirectional Transformers for
	Language Understanding},
	howpublished = {\url{https://arxiv.org/pdf/1810.04805}},
	note         = {Accédé le [12-05-2024]},
}

@misc{video_trans,
	title        = {Seq. 08 / Transformers},
	howpublished = {\url{https://www.youtube.com/watch?v=L3DGgzIbKz4&t=3666s}},
	note         = {Accédé le [12-05-2024]},
}


@misc{und_code_sa,
	title        = {Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attention, and Causal-Attention in LLMs},
	howpublished = {\url{https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention}},
	note         = {Accédé le [14-05-2024]},
}


@misc{openai_gpt,
	title        = {Improving Language Understanding
	by Generative Pre-Training},
	howpublished = {\url{https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf}},
	note         = {Accédé le [14-05-2024]},
}

@misc{robert,
	title        = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
	howpublished = {\url{https://arxiv.org/pdf/1907.11692}},
	note         = {Accédé le [15-05-2024]},
}

@misc{blue,
	title        = {GLUE: A MULTI-TASK BENCHMARK AND ANALYSIS
	PLATFORM FOR NATURAL LANGUAGE UNDERSTAND-
	ING},
	howpublished = {\url{https://openreview.net/pdf?id=rJ4km2R5t7}},
	note         = {Accédé le [15-05-2024]},
}

@misc{sbert,
	title        = {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
	howpublished = {\url{https://arxiv.org/abs/1908.10084}},
	note         = {Accédé le [17-05-2024]},
}

@misc{sts,
	title        = {STS Benchmark (Semantic Textual Similarity) },
	howpublished = {\url{https://paperswithcode.com/dataset/sts-benchmark}},
	note         = {Accédé le [17-05-2024]},
}

@misc{sts,
	title        = {SNLI (Stanford Natural Language Inference)  },
	howpublished = {\url{https://paperswithcode.com/dataset/snli}},
	note         = {Accédé le [17-05-2024]},
}



